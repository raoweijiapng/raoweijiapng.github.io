<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Kafka源码之Producer⽣产者流程 | WeiJia_Rao</title><meta name="keywords" content="Java Hadoop"><meta name="author" content="WeiJia Rao"><meta name="copyright" content="WeiJia Rao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Producer示例 ⾸先我们先通过⼀段代码来展示 KafkaProducer 的使⽤⽅法。 在下⾯的示例中，我们使⽤ KafkaProducer 实现 向kafka发送消息的功能。 在示例程序中，⾸先将 KafkaProduce 使⽤的配置写⼊到 Properties 中，每项配置的具体含义在注释中进⾏解释。之后以此 Properties 对象为参数构造 KafkaProducer 对象，最后通">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka源码之Producer⽣产者流程">
<meta property="og:url" content="https://raoweijiapng.gitee.io/posts/1412138553/index.html">
<meta property="og:site_name" content="WeiJia_Rao">
<meta property="og:description" content="Producer示例 ⾸先我们先通过⼀段代码来展示 KafkaProducer 的使⽤⽅法。 在下⾯的示例中，我们使⽤ KafkaProducer 实现 向kafka发送消息的功能。 在示例程序中，⾸先将 KafkaProduce 使⽤的配置写⼊到 Properties 中，每项配置的具体含义在注释中进⾏解释。之后以此 Properties 对象为参数构造 KafkaProducer 对象，最后通">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raoweijiapng.gitee.io/img/7.jpg">
<meta property="article:published_time" content="2022-08-01T08:22:36.000Z">
<meta property="article:modified_time" content="2022-08-01T09:56:18.000Z">
<meta property="article:author" content="WeiJia Rao">
<meta property="article:tag" content="Java Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raoweijiapng.gitee.io/img/7.jpg"><link rel="shortcut icon" href="/img/networkPhoto.jpg"><link rel="canonical" href="https://raoweijiapng.gitee.io/posts/1412138553/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?a9e49a68498fd088e63e2fe8907ca570";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Kafka源码之Producer⽣产者流程',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-08-01 17:56:18'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/authorPhoto.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">409</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">64</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">57</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/7.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">WeiJia_Rao</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Kafka源码之Producer⽣产者流程</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-01T08:22:36.000Z" title="发表于 2022-08-01 16:22:36">2022-08-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-08-01T09:56:18.000Z" title="更新于 2022-08-01 17:56:18">2022-08-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Kafka/">Kafka</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>16分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Kafka源码之Producer⽣产者流程"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="Producer示例">Producer示例</h2>
<p>⾸先我们先通过⼀段代码来展示 KafkaProducer 的使⽤⽅法。</p>
<p>在下⾯的示例中，我们使⽤ KafkaProducer 实现 向kafka发送消息的功能。</p>
<p>在示例程序中，⾸先将 KafkaProduce 使⽤的配置写⼊到 Properties 中，每项配置的具体含义在注释中进⾏解释。之后以此 Properties 对象为参数构造 KafkaProducer 对象，最后通过 send ⽅法完成发送，代码中包含同步发送、异步发送两种情况。</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">    <span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">    <span class="comment">// 客户端id</span></span><br><span class="line">    props.put(<span class="string">&quot;client.id&quot;</span>, <span class="string">&quot;KafkaProducerDemo&quot;</span>);</span><br><span class="line">    <span class="comment">// kafka地址,列表格式为host1:port1,host2:port2,…，⽆需添加所有的集群地址，kafka会根据提供的地址发现其他的地址（建议多提供⼏个，以防提供的服务器关闭）</span></span><br><span class="line">    props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;localhost:9092&quot;</span>);</span><br><span class="line">    <span class="comment">// 发送返回应答⽅式</span></span><br><span class="line">    <span class="comment">// 0:Producer 往集群发送数据不需要等到集群的返回，不确保消息发送成功。安全性最低但是效率最⾼。</span></span><br><span class="line">    <span class="comment">// 1:Producer 往集群发送数据只要 Leader 应答就可以发送下⼀条，只确保Leader接收成功。</span></span><br><span class="line">    <span class="comment">// -1或者all：Producer 往集群发送数据需要所有的ISR Follower都完成从Leader的同步才会发送下⼀条，确保Leader发送成功和所有的副本都成功接收。安全性最⾼，但是效率最低。</span></span><br><span class="line">    props.put(<span class="string">&quot;acks&quot;</span>, <span class="string">&quot;all&quot;</span>);</span><br><span class="line">    <span class="comment">// 重试次数</span></span><br><span class="line">    props.put(<span class="string">&quot;retries&quot;</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="comment">// 重试间隔时间</span></span><br><span class="line">    props.put(<span class="string">&quot;retries.backoff.ms&quot;</span>, <span class="number">100</span>);</span><br><span class="line">    <span class="comment">// 批量发送的⼤⼩</span></span><br><span class="line">    props.put(<span class="string">&quot;batch.size&quot;</span>, <span class="number">16384</span>);</span><br><span class="line">    <span class="comment">// ⼀个Batch被创建之后，最多过多久，不管这个Batch有没有写满，都必须发送出去</span></span><br><span class="line">    props.put(<span class="string">&quot;linger.ms&quot;</span>, <span class="number">10</span>);</span><br><span class="line">    <span class="comment">// 缓冲区⼤⼩</span></span><br><span class="line">    props.put(<span class="string">&quot;buffer.memory&quot;</span>, <span class="number">33554432</span>);</span><br><span class="line">    <span class="comment">// key序列化⽅式</span></span><br><span class="line">    props.put(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">    <span class="comment">// value序列化⽅式</span></span><br><span class="line">    props.put(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">    <span class="comment">// topic</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">topic</span> <span class="operator">=</span> <span class="string">&quot;lagou_edu&quot;</span>;</span><br><span class="line">    Producer&lt;String, String&gt; producer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(props);</span><br><span class="line">    <span class="type">AtomicInteger</span> <span class="variable">count</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AtomicInteger</span>();</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">num</span> <span class="operator">=</span> count.get();</span><br><span class="line">        <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> Integer.toString(num);</span><br><span class="line">        <span class="type">String</span> <span class="variable">value</span> <span class="operator">=</span> Integer.toString(num);</span><br><span class="line">        ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(topic, key, value);</span><br><span class="line">        <span class="keyword">if</span> (num % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// 偶数异步发送</span></span><br><span class="line">            <span class="comment">// 第⼀个参数record封装了topic、key、value</span></span><br><span class="line">            <span class="comment">// 第⼆个参数是⼀个callback对象，当⽣产者接收到kafka发来的ACK确认消息时，会调⽤此CallBack对象的onComplete⽅法</span></span><br><span class="line">            producer.send(record, (recordMetadata, e) -&gt; &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;num:&quot;</span> + num + <span class="string">&quot; topic:&quot;</span> + recordMetadata.topic() + <span class="string">&quot; offset:&quot;</span> + recordMetadata.offset());</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 同步发送</span></span><br><span class="line">            <span class="comment">// KafkaProducer.send⽅法返回的类型是Future&lt;RecordMetadata&gt;，通过get⽅法阻塞当前线程，等待kafka服务端ACK响应</span></span><br><span class="line">            producer.send(record).get();</span><br><span class="line">        &#125;</span><br><span class="line">        count.incrementAndGet();</span><br><span class="line">        TimeUnit.MILLISECONDS.sleep(<span class="number">100</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;    </span><br></pre></td></tr></table></figure>
<h3 id="同步发送">同步发送</h3>
<ol>
<li>KafkaProducer.send⽅法返回的类型是Future<RecordMetadata>，通过get⽅法阻塞当前线程，等待kafka服务端ACK响应</li>
</ol>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">producer.send(record).get()</span><br></pre></td></tr></table></figure>
<h3 id="异步发送">异步发送</h3>
<ol>
<li>
<p>第⼀个参数record封装了topic、key、value</p>
</li>
<li>
<p>第⼆个参数是⼀个callback对象，当⽣产者接收到kafka发来的ACK确认消息时，会调⽤此CallBack对象的onComplete⽅法</p>
</li>
</ol>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">producer.send(record, (recordMetadata, e) -&gt; &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;num:&quot;</span> + num + <span class="string">&quot; topic:&quot;</span> + recordMetadata.topic() + <span class="string">&quot; offset:&quot;</span> + recordMetadata.offset());</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h2 id="KafkaProducer实例化">KafkaProducer实例化</h2>
<p>了解了 KafkaProducer 的基本使⽤，开始深⼊了解的KafkaProducer原理和实现，先看⼀下构造⽅法核⼼逻辑。</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="title function_">KafkaProducer</span><span class="params">(ProducerConfig config, Serializer&lt;K&gt; keySerializer, Serializer&lt;V&gt; valueSerializer)</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 获取⽤户的配置</span></span><br><span class="line">        Map&lt;String, Object&gt; userProvidedConfigs = config.originals();</span><br><span class="line">        <span class="built_in">this</span>.producerConfig = config;</span><br><span class="line">        <span class="comment">// 系统时间</span></span><br><span class="line">        <span class="built_in">this</span>.time = Time.SYSTEM;</span><br><span class="line">        <span class="comment">// 获取client.id配置</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">clientId</span> <span class="operator">=</span> config.getString(ProducerConfig.CLIENT_ID_CONFIG);</span><br><span class="line">        <span class="comment">// 如果client.id为空，设置默认值:producer-1</span></span><br><span class="line">        <span class="keyword">if</span> (clientId.length() &lt;= <span class="number">0</span>)</span><br><span class="line">            clientId = <span class="string">&quot;producer-&quot;</span> + PRODUCER_CLIENT_ID_SEQUENCE.getAndIncrement();</span><br><span class="line">            <span class="built_in">this</span>.clientId = clientId;</span><br><span class="line">            <span class="comment">// 获取事务id,如果没有配置则为null</span></span><br><span class="line">            <span class="type">String</span> <span class="variable">transactionalId</span> <span class="operator">=</span> userProvidedConfigs.containsKey(ProducerConfig.TRANSACTIONAL_ID_CONFIG) ? (String)userProvidedConfigs.get(ProducerConfig.TRANSACTIONAL_ID_CONFIG) : <span class="literal">null</span>;</span><br><span class="line">            LogContext logContext;</span><br><span class="line">            <span class="keyword">if</span> (transactionalId == <span class="literal">null</span>)</span><br><span class="line">                logContext = <span class="keyword">new</span> <span class="title class_">LogContext</span>(String.format(<span class="string">&quot;[Producer clientId=%s] &quot;</span>,clientId));</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                logContext = <span class="keyword">new</span> <span class="title class_">LogContext</span>(String.format(<span class="string">&quot;[Producer clientId=%s,transactionalId=%s] &quot;</span>, clientId, transactionalId));</span><br><span class="line">            log = logContext.logger(KafkaProducer.class);</span><br><span class="line">            log.trace(<span class="string">&quot;Starting the Kafka producer&quot;</span>);</span><br><span class="line">            <span class="comment">// 创建client-id的监控map</span></span><br><span class="line">            Map&lt;String, String&gt; metricTags = Collections.singletonMap(<span class="string">&quot;client-id&quot;</span>, clientId);</span><br><span class="line">            <span class="comment">// 设置监控配置，包含样本量、取样时间窗⼝、记录级别</span></span><br><span class="line">            <span class="type">MetricConfig</span> <span class="variable">metricConfig</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MetricConfig</span>().samples(config.getInt(ProducerConfig.METRICS_NUM_SAMPLES_CONFIG)).timeWindow(config.getLong(ProducerConfig.METRICS_SAMPLE_WINDOW_MS_CONFIG),TimeUnit.MILLISECONDS).recordLevel(Sensor.RecordingLevel.forName(config.getString(ProducerConfig.METRICS_RECORDING_LEVEL_CONFIG))).tags(metricTags);</span><br><span class="line">            <span class="comment">// 监控数据上报类</span></span><br><span class="line">            List&lt;MetricsReporter&gt; reporters = config.getConfiguredInstances(ProducerConfig.METRIC_REPORTER_CLASSES_CONFIG,  MetricsReporter.class);</span><br><span class="line">            reporters.add(<span class="keyword">new</span> <span class="title class_">JmxReporter</span>(JMX_PREFIX));</span><br><span class="line">            <span class="built_in">this</span>.metrics = <span class="keyword">new</span> <span class="title class_">Metrics</span>(metricConfig, reporters, time);</span><br><span class="line">            <span class="comment">// ⽣成⽣产者监控</span></span><br><span class="line">            <span class="type">ProducerMetrics</span> <span class="variable">metricsRegistry</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ProducerMetrics</span>(<span class="built_in">this</span>.metrics);</span><br><span class="line">            <span class="comment">// 分区类</span></span><br><span class="line">            <span class="built_in">this</span>.partitioner = config.getConfiguredInstance(ProducerConfig.PARTITIONER_CLASS_CONFIG, Partitioner.class);</span><br><span class="line">            <span class="comment">// 重试时间 retry.backoff.ms 默认100ms</span></span><br><span class="line">            <span class="type">long</span> <span class="variable">retryBackoffMs</span> <span class="operator">=</span> config.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG);</span><br><span class="line">            <span class="keyword">if</span> (keySerializer == <span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="comment">// 反射⽣成key序列化⽅式</span></span><br><span class="line">                <span class="built_in">this</span>.keySerializer = ensureExtended(config.getConfiguredInstance(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,  Serializer.class));</span><br><span class="line">                <span class="built_in">this</span>.keySerializer.configure(config.originals(), <span class="literal">true</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                config.ignore(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);</span><br><span class="line">                <span class="built_in">this</span>.keySerializer = ensureExtended(keySerializer);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (valueSerializer == <span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="comment">// 反射⽣成key序列化⽅式</span></span><br><span class="line">                <span class="built_in">this</span>.valueSerializer = ensureExtended(config.getConfiguredInstance(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,  Serializer.class));</span><br><span class="line">                <span class="built_in">this</span>.valueSerializer.configure(config.originals(), <span class="literal">false</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                config.ignore(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);</span><br><span class="line">                <span class="built_in">this</span>.valueSerializer = ensureExtended(valueSerializer);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// load interceptors and make sure they get clientId</span></span><br><span class="line">            <span class="comment">// 确认client.id添加到⽤户的配置⾥⾯</span></span><br><span class="line">            userProvidedConfigs.put(ProducerConfig.CLIENT_ID_CONFIG, clientId);</span><br><span class="line">            <span class="comment">// 获取多个拦截器,为空则不处理</span></span><br><span class="line">            List&lt;ProducerInterceptor&lt;K, V&gt;&gt; interceptorList = (List) (<span class="keyword">new</span> <span class="title class_">ProducerConfig</span>(userProvidedConfigs, <span class="literal">false</span>)).getConfiguredInstances(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,  ProducerInterceptor.class);</span><br><span class="line">            <span class="built_in">this</span>.interceptors = interceptorList.isEmpty() ? <span class="literal">null</span> : <span class="keyword">new</span> <span class="title class_">ProducerInterceptors</span>&lt;&gt;(interceptorList);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 集群资源监听器,在元数据变更时会有通知</span></span><br><span class="line">            <span class="type">ClusterResourceListeners</span> <span class="variable">clusterResourceListeners</span> <span class="operator">=</span> configureClusterResourceListeners(keySerializer, valueSerializer, interceptorList, reporters);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// ⽣产者每隔⼀段时间都要去更新⼀下集群的元数据,默认5分钟</span></span><br><span class="line">            <span class="built_in">this</span>.metadata = <span class="keyword">new</span> <span class="title class_">Metadata</span>(retryBackoffMs, config.getLong(ProducerConfig.METADATA_MAX_AGE_CONFIG), <span class="literal">true</span>, <span class="literal">true</span>, clusterResourceListeners);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// ⽣产者往服务端发送消息的时候，规定⼀条消息最⼤多⼤？</span></span><br><span class="line">            <span class="comment">// 如果你超过了这个规定消息的⼤⼩，你的消息就不能发送过去。</span></span><br><span class="line">            <span class="comment">// 默认是1M，这个值偏⼩，在⽣产环境中，我们需要修改这个值。</span></span><br><span class="line">            <span class="comment">// 经验值是10M。但是⼤家也可以根据⾃⼰公司的情况来。</span></span><br><span class="line">            <span class="built_in">this</span>.maxRequestSize = config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG);</span><br><span class="line">            <span class="comment">//指的是缓存⼤⼩</span></span><br><span class="line">            <span class="comment">//默认值是32M，这个值⼀般是够⽤，如果有特殊情况的时候，我们可以去修改这个值。</span></span><br><span class="line">            <span class="built_in">this</span>.totalMemorySize = config.getLong(ProducerConfig.BUFFER_MEMORY_CONFIG);</span><br><span class="line">            <span class="comment">// kafka是⽀持压缩数据的，可以设置压缩格式,默认是不压缩，⽀持gzip、snappy、lz4</span></span><br><span class="line">            <span class="comment">// ⼀次发送出去的消息就更多。⽣产者这⼉会消耗更多的cpu.</span></span><br><span class="line">            <span class="built_in">this</span>.compressionType = CompressionType.forName(config.getString(ProducerConfig.COMPRESSION_TYPE_CONFIG));</span><br><span class="line">            <span class="comment">// 配置控制了KafkaProducer.send()并将KafkaProducer.partitionsFor()被阻塞多⻓时间,由于缓冲区已满或元数据不可⽤，这些⽅法可能会被阻塞⽌</span></span><br><span class="line">            <span class="built_in">this</span>.maxBlockTimeMs = config.getLong(ProducerConfig.MAX_BLOCK_MS_CONFIG);</span><br><span class="line">            <span class="comment">// 控制客户端等待请求响应的最⻓时间。如果在超时过去之前未收到响应，客户端将在必要时重新发送请求，或者如果重试耗尽，请求失败</span></span><br><span class="line">            <span class="built_in">this</span>.requestTimeoutMs = config.getInt(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG);</span><br><span class="line">            <span class="comment">// 事务管理器</span></span><br><span class="line">            <span class="built_in">this</span>.transactionManager = configureTransactionState(config, logContext, log);</span><br><span class="line">            <span class="comment">// 重试次数</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">retries</span> <span class="operator">=</span> configureRetries(config, transactionManager != <span class="literal">null</span>, log);</span><br><span class="line">            <span class="comment">// 使⽤幂等性，需要将 enable.idempotence 配置项设置为true。并且它对单个分区的发送，⼀次性最多发送5条</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">maxInflightRequests</span> <span class="operator">=</span> configureInflightRequests(config, transactionManager != <span class="literal">null</span>);</span><br><span class="line">            <span class="comment">// 如果开启了幂等性，但是⽤户指定的ack不为 -1，则会抛出异常</span></span><br><span class="line">            <span class="type">short</span> <span class="variable">acks</span> <span class="operator">=</span> configureAcks(config, transactionManager != <span class="literal">null</span>, log);</span><br><span class="line">            <span class="built_in">this</span>.apiVersions = <span class="keyword">new</span> <span class="title class_">ApiVersions</span>();</span><br><span class="line">            <span class="comment">// 创建核⼼组件：记录累加器</span></span><br><span class="line">            <span class="built_in">this</span>.accumulator = <span class="keyword">new</span> <span class="title class_">RecordAccumulator</span>(logContext, config.getInt(ProducerConfig.BATCH_SIZE_CONFIG), <span class="built_in">this</span>.totalMemorySize, <span class="built_in">this</span>.compressionType, config.getLong(ProducerConfig.LINGER_MS_CONFIG), retryBackoffMs, metrics, time, apiVersions, transactionManager);</span><br><span class="line">            <span class="comment">// 获取broker地址列表</span></span><br><span class="line">            List&lt;InetSocketAddress&gt; addresses = ClientUtils.parseAndValidateAddresses(config.getList(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG));</span><br><span class="line">            <span class="comment">// 更新元数据</span></span><br><span class="line">            <span class="built_in">this</span>.metadata.update(Cluster.bootstrap(addresses), Collections. &lt;String&gt;emptySet(), time.milliseconds());</span><br><span class="line">            <span class="comment">// 创建通道，是否需要加密</span></span><br><span class="line">            <span class="type">ChannelBuilder</span> <span class="variable">channelBuilder</span> <span class="operator">=</span> ClientUtils.createChannelBuilder(config);</span><br><span class="line">            <span class="type">Sensor</span> <span class="variable">throttleTimeSensor</span> <span class="operator">=</span> Sender.throttleTimeSensor(metricsRegistry.senderMetrics);</span><br><span class="line">            <span class="comment">// 初始化了⼀个重要的管理⽹路的组件</span></span><br><span class="line">            <span class="comment">// connections.max.idle.ms: 默认值是9分钟, ⼀个⽹络连接最多空闲多久，超过这个空闲时间，就关闭这个⽹络连接。</span></span><br><span class="line">            <span class="comment">// max.in.flight.requests.per.connection：默认是5, producer向broker发送数据的时候，其实是有多个⽹络连接。每个⽹络连接可以忍受 producer端发送给broker 消息然后消息没有响应的个数</span></span><br><span class="line">            <span class="type">NetworkClient</span> <span class="variable">client</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">NetworkClient</span>(<span class="keyword">new</span> <span class="title class_">Selector</span>(config.getLong(ProducerConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG),  <span class="built_in">this</span>.metrics, time, <span class="string">&quot;producer&quot;</span>, channelBuilder, logContext), <span class="built_in">this</span>.metadata, clientId, maxInflightRequests, config.getLong(ProducerConfig.RECONNECT_BACKOFF_MS_CONFIG), config.getLong(ProducerConfig.RECONNECT_BACKOFF_MAX_MS_CONFIG), config.getInt(ProducerConfig.SEND_BUFFER_CONFIG), config.getInt(ProducerConfig.RECEIVE_BUFFER_CONFIG), <span class="built_in">this</span>.requestTimeoutMs, time, <span class="literal">true</span>, apiVersions, throttleTimeSensor, logContext);</span><br><span class="line">            <span class="comment">// 发送线程</span></span><br><span class="line">            <span class="built_in">this</span>.sender = <span class="keyword">new</span> <span class="title class_">Sender</span>(logContext, client, <span class="built_in">this</span>.metadata, <span class="built_in">this</span>.accumulator, maxInflightRequests == <span class="number">1</span>, config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG), acks, retries, metricsRegistry.senderMetrics, Time.SYSTEM, <span class="built_in">this</span>.requestTimeoutMs, config.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG), <span class="built_in">this</span>.transactionManager, apiVersions);</span><br><span class="line">            <span class="comment">// 线程名称</span></span><br><span class="line">            <span class="type">String</span> <span class="variable">ioThreadName</span> <span class="operator">=</span> NETWORK_THREAD_PREFIX + <span class="string">&quot; | &quot;</span> + clientId;</span><br><span class="line">            <span class="comment">// 启动守护线程</span></span><br><span class="line">            <span class="built_in">this</span>.ioThread = <span class="keyword">new</span> <span class="title class_">KafkaThread</span>(ioThreadName, <span class="built_in">this</span>.sender, <span class="literal">true</span>);</span><br><span class="line">            <span class="built_in">this</span>.ioThread.start();</span><br><span class="line">            <span class="built_in">this</span>.errors = <span class="built_in">this</span>.metrics.sensor(<span class="string">&quot;errors&quot;</span>);</span><br><span class="line">            <span class="comment">// 把⽤户配置的参数，但是没有⽤到的打印出来</span></span><br><span class="line">            config.logUnused();</span><br><span class="line">            AppInfoParser.registerAppInfo(JMX_PREFIX, clientId, metrics);</span><br><span class="line">            log.debug(<span class="string">&quot;Kafka producer started&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">            <span class="comment">// call close methods if internal objects are already constructed this is to prevent resource leak. see KAFKA-2121</span></span><br><span class="line">            close(<span class="number">0</span>, TimeUnit.MILLISECONDS, <span class="literal">true</span>);</span><br><span class="line">            <span class="comment">// now propagate the exception</span></span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">KafkaException</span>(<span class="string">&quot;Failed to construct kafka producer&quot;</span>, t);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="消息发送过程">消息发送过程</h2>
<p>Kafka消息实际发送以 send ⽅法为⼊⼝：</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title function_">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> &#123;</span><br><span class="line">    <span class="comment">// intercept the record, which can be potentially modified; this method does not throw exceptions</span></span><br><span class="line">    ProducerRecord&lt;K, V&gt; interceptedRecord = <span class="built_in">this</span>.interceptors == <span class="literal">null</span> ? record : <span class="built_in">this</span>.interceptors.onSend(record);</span><br><span class="line">    <span class="keyword">return</span> doSend(interceptedRecord, callback);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="拦截器-3">拦截器</h3>
<p>⾸先⽅法会先进⼊拦截器集合 ProducerInterceptors ， onSend ⽅法是遍历拦截器 onSend ⽅法，拦截器的⽬的是将数据处理加⼯， kafka 本身并没有给出默认的拦截器的实现。如果需要使⽤拦截器功能，必须⾃⼰实现ProducerInterceptor 接⼝。</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public ProducerRecord&lt;K, V&gt; onSend(ProducerRecord&lt;K, V&gt; record) &#123;</span><br><span class="line">    ProducerRecord&lt;K, V&gt; interceptRecord = record;</span><br><span class="line">    // 遍历所有拦截器，顺序执⾏，如果有异常只打印⽇志，不会向上抛出</span><br><span class="line">    for (ProducerInterceptor&lt;K, V&gt; interceptor : this.interceptors) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            interceptRecord = interceptor.onSend(interceptRecord);</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            // do not propagate interceptor exception, log and continue calling other interceptors</span><br><span class="line">            // be careful not to throw exception from here</span><br><span class="line">            if (record != null)</span><br><span class="line">                log.warn(&quot;Error executing interceptor onSend callback for topic: &#123;&#125;, partition: &#123;&#125;&quot;, record.topic(), record.partition(), e);</span><br><span class="line">            else</span><br><span class="line">                log.warn(&quot;Error executing interceptor onSend callback&quot;, e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return interceptRecord;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="拦截器核⼼逻辑">拦截器核⼼逻辑</h4>
<p>ProducerInterceptor 接⼝包括三个⽅法：</p>
<ul>
<li>
<ol>
<li>onSend(ProducerRecord)：该⽅法封装进KafkaProducer.send⽅法中，即它运⾏在⽤户主线程中的。</li>
</ol>
<p>Producer确保在消息被序列化以计算分区前调⽤该⽅法。⽤户可以在该⽅法中对消息做任何操作，但最好保证不要修改消息所属的topic和分区，否则会影响⽬标分区的计算</p>
</li>
<li>
<ol start="2">
<li>onAcknowledgement(RecordMetadata, Exception)：该⽅法会在消息被应答之前或消息发送失败时调⽤，并且通常都是在producer回调逻辑触发之前。onAcknowledgement运⾏在producer的IO线程中，因此不要在该⽅法中放⼊很重的逻辑，否则会拖慢producer的消息发送效率</li>
</ol>
</li>
<li>
<ol start="3">
<li>close：关闭interceptor，主要⽤于执⾏⼀些资源清理⼯作</li>
</ol>
</li>
<li>
<ol start="4">
<li>拦截器可能被运⾏在多个线程中，因此在具体实现时⽤户需要⾃⾏确保线程安全。另外倘若指定了多个interceptor，则producer将按照指定顺序调⽤它们，并仅仅是捕获每个interceptor可能抛出的异常记录到错误⽇志中⽽⾮在向上传递。</li>
</ol>
</li>
</ul>
<h3 id="发送五步骤">发送五步骤</h3>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Future&lt;RecordMetadata&gt; <span class="title function_">doSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> &#123;</span><br><span class="line">    <span class="comment">// ⾸先创建⼀个主题分区类</span></span><br><span class="line">    <span class="type">TopicPartition</span> <span class="variable">tp</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// first make sure the metadata for the topic is available</span></span><br><span class="line">        <span class="comment">// ⾸先确保该topic的元数据可⽤</span></span><br><span class="line">        <span class="type">ClusterAndWaitTime</span> <span class="variable">clusterAndWaitTime</span> <span class="operator">=</span> waitOnMetadata(record.topic(),record.partition(), maxBlockTimeMs);</span><br><span class="line">        <span class="type">long</span> <span class="variable">remainingWaitMs</span> <span class="operator">=</span> Math.max(<span class="number">0</span>, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);</span><br><span class="line">        <span class="type">Cluster</span> <span class="variable">cluster</span> <span class="operator">=</span> clusterAndWaitTime.cluster;</span><br><span class="line">        <span class="comment">// 序列化 record 的 key 和 value</span></span><br><span class="line">        <span class="type">byte</span>[] serializedKey;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            serializedKey = keySerializer.serialize(record.topic(),</span><br><span class="line">            record.headers(), record.key());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">SerializationException</span>(<span class="string">&quot;Can&#x27;t convert key of class &quot;</span> +</span><br><span class="line">            record.key().getClass().getName() +  <span class="string">&quot; to class &quot;</span> + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() + <span class="string">&quot; specified in key.serializer&quot;</span>, cce);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">byte</span>[] serializedValue;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            serializedValue = valueSerializer.serialize(record.topic(),</span><br><span class="line">            record.headers(), record.value());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">SerializationException</span>(<span class="string">&quot;Can&#x27;t convert value of class &quot;</span> + record.value().getClass().getName() + <span class="string">&quot; to class &quot;</span> + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() + <span class="string">&quot; specified in value.serializer&quot;</span>, cce);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 获取该 record 要发送到的 partition</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">partition</span> <span class="operator">=</span> partition(record, serializedKey, serializedValue, cluster);</span><br><span class="line">        tp = <span class="keyword">new</span> <span class="title class_">TopicPartition</span>(record.topic(), partition);</span><br><span class="line">        <span class="comment">// 给header设置只读</span></span><br><span class="line">        setReadOnly(record.headers());</span><br><span class="line">        Header[] headers = record.headers().toArray();</span><br><span class="line">        <span class="type">int</span> <span class="variable">serializedSize</span> <span class="operator">=</span> AbstractRecords.estimateSizeInBytesUpperBound(apiVersions.maxUsableProduceMagic(), compressionType, serializedKey, serializedValue, headers);</span><br><span class="line">        ensureValidRecordSize(serializedSize);</span><br><span class="line">        <span class="type">long</span> <span class="variable">timestamp</span> <span class="operator">=</span> record.timestamp() == <span class="literal">null</span> ? time.milliseconds() : record.timestamp();</span><br><span class="line">        log.trace(<span class="string">&quot;Sending record &#123;&#125; with callback &#123;&#125; to topic &#123;&#125; partition &#123;&#125;&quot;</span>, record, callback, record.topic(), partition);</span><br><span class="line">        <span class="comment">// producer callback will make sure to call both &#x27;callback&#x27; and interceptor callback</span></span><br><span class="line">        <span class="type">Callback</span> <span class="variable">interceptCallback</span> <span class="operator">=</span> <span class="built_in">this</span>.interceptors == <span class="literal">null</span> ? callback : <span class="keyword">new</span> <span class="title class_">InterceptorCallback</span>&lt;&gt;(callback, <span class="built_in">this</span>.interceptors, tp);</span><br><span class="line">        <span class="keyword">if</span> (transactionManager != <span class="literal">null</span> &amp;&amp; transactionManager.isTransactional())</span><br><span class="line">            transactionManager.maybeAddPartitionToTransaction(tp);</span><br><span class="line">            <span class="comment">// 向 accumulator 中追加 record 数据，数据会先进⾏缓存</span></span><br><span class="line">        RecordAccumulator.<span class="type">RecordAppendResult</span> <span class="variable">result</span> <span class="operator">=</span> accumulator.append(tp, timestamp, serializedKey, serializedValue, headers, interceptCallback, remainingWaitMs);</span><br><span class="line">        <span class="comment">// 如果追加完数据后，对应的 RecordBatch 已经达到了 batch.size 的⼤⼩（或者batch的剩余空间不⾜以添加下⼀条 Record），则唤醒 sender 线程发送数据。</span></span><br><span class="line">        <span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">            log.trace(<span class="string">&quot;Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch&quot;</span>, record.topic(), partition);</span><br><span class="line">            <span class="built_in">this</span>.sender.wakeup();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result.future;</span><br><span class="line">        <span class="comment">// handling exceptions and record the errors;</span></span><br><span class="line">        <span class="comment">// for API exceptions return them in the future,</span></span><br><span class="line">        <span class="comment">// for other exceptions throw directly</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (ApiException e) &#123;</span><br><span class="line">        log.debug(<span class="string">&quot;Exception occurred during message send:&quot;</span>, e);</span><br><span class="line">        <span class="keyword">if</span> (callback != <span class="literal">null</span>)</span><br><span class="line">            callback.onCompletion(<span class="literal">null</span>, e);</span><br><span class="line">        <span class="built_in">this</span>.errors.record();</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.interceptors != <span class="literal">null</span>)</span><br><span class="line">            <span class="built_in">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">FutureFailure</span>(e);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">        <span class="built_in">this</span>.errors.record();</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.interceptors != <span class="literal">null</span>)</span><br><span class="line">            <span class="built_in">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">InterruptException</span>(e);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (BufferExhaustedException e) &#123;</span><br><span class="line">        <span class="built_in">this</span>.errors.record();</span><br><span class="line">        <span class="built_in">this</span>.metrics.sensor(<span class="string">&quot;buffer-exhausted-records&quot;</span>).record();</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.interceptors != <span class="literal">null</span>)</span><br><span class="line">            <span class="built_in">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (KafkaException e) &#123;</span><br><span class="line">        <span class="built_in">this</span>.errors.record();</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.interceptors != <span class="literal">null</span>)</span><br><span class="line">            <span class="built_in">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="comment">// we notify interceptor about all exceptions, since onSend is called before anything else in this method</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.interceptors != <span class="literal">null</span>)</span><br><span class="line">            <span class="built_in">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>
<ol>
<li>Producer 通过 waitOnMetadata() ⽅法来获取对应 topic 的 metadata 信息，需要先该 topic 是可⽤的</li>
</ol>
</li>
<li>
<ol start="2">
<li>Producer 端对 record 的 key 和 value 值进⾏序列化操作，在 Consumer 端再进⾏相应的反序列化</li>
</ol>
</li>
<li>
<ol start="3">
<li>获取partition值，具体分为下⾯三种情况：</li>
</ol>
<ul>
<li>
<ol>
<li>指明 partition 的情况下，直接将指明的值直接作为 partiton 值</li>
</ol>
</li>
<li>
<ol start="2">
<li>没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进⾏取余得到partition 值</li>
</ol>
</li>
<li>
<ol start="3">
<li>既没有 partition 值⼜没有 key 值的情况下，第⼀次调⽤时随机⽣成⼀个整数（后⾯每次调⽤在这个整数上⾃增），将这个值与 topic 可⽤的 partition 总数取余得到 partition 值，也就是常说的round-robin 算法</li>
</ol>
</li>
<li>
<ol start="4">
<li>Producer 默认使⽤的 partitioner 是 org.apache.kafka.clients.producer.internals.DefaultPartitioner</li>
</ol>
</li>
</ul>
</li>
<li>
<ol start="4">
<li>向 accumulator 写数据，先将 record 写⼊到 buffer 中，当达到⼀个 batch.size 的⼤⼩时，再唤起 sender 线程去发送 RecordBatch，这⾥仔细分析⼀下Producer是如何向buffer写⼊数据的</li>
</ol>
<ul>
<li>
<ol>
<li>获取该 topic-partition 对应的 queue，没有的话会创建⼀个空的 queue</li>
</ol>
</li>
<li>
<ol start="2">
<li>向 queue 中追加数据，先获取 queue 中最新加⼊的那个 RecordBatch，如果不存在或者存在但剩余空余不⾜以添加本条 record 则返回 null，成功写⼊的话直接返回结果，写⼊成功</li>
</ol>
</li>
<li>
<ol start="3">
<li>创建⼀个新的 RecordBatch，初始化内存⼤⼩根据 max(batch.size, Records.LOG_OVERHEAD + Record.recordSize(key, value)) 来确定（防⽌单条 record 过⼤的情况）</li>
</ol>
</li>
<li>
<ol start="4">
<li>向新建的 RecordBatch 写⼊ record，并将 RecordBatch 添加到 queue 中，返回结果，写⼊成功</li>
</ol>
</li>
</ul>
</li>
<li>
<ol start="5">
<li>发送 RecordBatch，当 record 写⼊成功后，如果发现 RecordBatch 已满⾜发送的条件（通常是 queue 中有多个 batch，那么最先添加的那些 batch 肯定是可以发送了），那么就会唤醒 sender 线程，发送RecordBatch 。sender 线程对 RecordBatch 的处理是在 run() ⽅法中进⾏的，该⽅法具体实现如下：</li>
</ol>
<ul>
<li>
<ol>
<li>获取那些已经可以发送的 RecordBatch 对应的 nodes</li>
</ol>
</li>
<li>
<ol start="2">
<li>如果与node 没有连接（如果可以连接,同时初始化该连接）,就证明该 node 暂时不能发送数据,暂时移除该 node</li>
</ol>
</li>
<li>
<ol start="3">
<li>返回该 node 对应的所有可以发送的 RecordBatch 组成的 batches（key 是 <a target="_blank" rel="noopener" href="http://node.id">node.id</a>）,并将 RecordBatch 从对应的 queue 中移除</li>
</ol>
</li>
<li>
<ol start="4">
<li>将由于元数据不可⽤⽽导致发送超时的 RecordBatch 移除</li>
</ol>
</li>
<li>
<ol start="5">
<li>发送 RecordBatch</li>
</ol>
</li>
</ul>
</li>
</ul>
<h3 id="MetaData更新机制">MetaData更新机制</h3>
<ul>
<li>
<ol>
<li>metadata.requestUpdate() 将 metadata 的 needUpdate 变量设置为 true（强制更新），并返回当前的版本号（version），通过版本号来判断 metadata 是否完成更新</li>
</ol>
</li>
<li>
<ol start="2">
<li>sender.wakeup() 唤醒 sender 线程，sender 线程⼜会去唤醒NetworkClient线程去更新</li>
</ol>
</li>
<li>
<ol start="3">
<li>metadata.awaitUpdate(version, remainingWaitMs) 等待 metadata 的更新</li>
</ol>
</li>
<li>
<ol start="4">
<li>所以，每次 Producer 请求更新 metadata 时，会有以下⼏种情况:</li>
</ol>
<ul>
<li>
<ol>
<li>如果 node 可以发送请求，则直接发送请求</li>
</ol>
</li>
<li>
<ol start="2">
<li>如果该 node 正在建⽴连接，则直接返回</li>
</ol>
</li>
<li>
<ol start="3">
<li>如果该 node 还没建⽴连接，则向 broker 初始化链接</li>
</ol>
</li>
</ul>
</li>
<li>
<ol start="5">
<li>NetworkClient的poll⽅法中判断是否需要更新meta数据， handleCompletedReceives 处理 metadata 的更新，最终是调⽤的 DefaultMetadataUpdater 中的 handleCompletedMetadataResponse ⽅法处理</li>
</ol>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://raoweijiapng.gitee.io">WeiJia Rao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://raoweijiapng.gitee.io/posts/1412138553/">https://raoweijiapng.gitee.io/posts/1412138553/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://raoweijiapng.gitee.io" target="_blank">WeiJia_Rao</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/7.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/3092409380/"><img class="prev-cover" src="/img/6.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Kafka源码之Topic创建流程</div></div></a></div><div class="next-post pull-right"><a href="/posts/1852269/"><img class="next-cover" src="/img/9.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Kafka源码之Consumer消费者流程</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/authorPhoto.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">WeiJia Rao</div><div class="author-info__description">饶唯甲的个人博客网站,用于记录平时的学习笔记并展示。努力学习吧,少年!</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">409</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">64</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">57</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/raoweijiapng"><i class="fab fa-github"></i><span>My GitHub</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="mailto:raoweijia@outlook.com" target="_blank" title="邮箱"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://space.bilibili.com/217971296?spm_id_from=333.1007.0.0" target="_blank" title="哔哩哔哩"><i class="fa-brands fa-bilibili"></i></a><a class="social-icon" href="https://weibo.com/p/1005057628848053" target="_blank" title="微博"><i class="fa-brands fa-weibo"></i></a><a class="social-icon" href="https://www.zhihu.com/people/kan-kan-ni-66-95" target="_blank" title="知乎"><i class="fa-brands fa-zhihu"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Producer%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.</span> <span class="toc-text">Producer示例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8C%E6%AD%A5%E5%8F%91%E9%80%81"><span class="toc-number">1.1.</span> <span class="toc-text">同步发送</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81"><span class="toc-number">1.2.</span> <span class="toc-text">异步发送</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KafkaProducer%E5%AE%9E%E4%BE%8B%E5%8C%96"><span class="toc-number">2.</span> <span class="toc-text">KafkaProducer实例化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%BF%87%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">消息发送过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%A6%E6%88%AA%E5%99%A8-3"><span class="toc-number">3.1.</span> <span class="toc-text">拦截器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8B%A6%E6%88%AA%E5%99%A8%E6%A0%B8%E2%BC%BC%E9%80%BB%E8%BE%91"><span class="toc-number">3.1.1.</span> <span class="toc-text">拦截器核⼼逻辑</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E9%80%81%E4%BA%94%E6%AD%A5%E9%AA%A4"><span class="toc-number">3.2.</span> <span class="toc-text">发送五步骤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MetaData%E6%9B%B4%E6%96%B0%E6%9C%BA%E5%88%B6"><span class="toc-number">3.3.</span> <span class="toc-text">MetaData更新机制</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/3367322272/" title="Linux安装部署高可用k8s集群和Kubesphere">Linux安装部署高可用k8s集群和Kubesphere</a><time datetime="2023-05-25T06:56:18.000Z" title="发表于 2023-05-25 14:56:18">2023-05-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/1799339243/" title="Linux安装部署KubeSphere基于k8s集群">Linux安装部署KubeSphere基于k8s集群</a><time datetime="2023-05-23T11:32:52.000Z" title="发表于 2023-05-23 19:32:52">2023-05-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/2751830321/" title="Linux安装部署高可用k8s集群">Linux安装部署高可用k8s集群</a><time datetime="2023-05-22T01:48:15.000Z" title="发表于 2023-05-22 09:48:15">2023-05-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/1833533627/" title="Linux安装部署docker">Linux安装部署docker</a><time datetime="2023-05-22T01:22:08.000Z" title="发表于 2023-05-22 09:22:08">2023-05-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/1312854160/" title="Java变量的线程安全分析">Java变量的线程安全分析</a><time datetime="2023-03-10T07:59:19.000Z" title="发表于 2023-03-10 15:59:19">2023-03-10</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/footer_img.png')"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2023 By WeiJia Rao</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://raoweijiapng.gitee.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><div class="aplayer no-destroy" data-id="60198" data-server="netease" data-type="playlist" data-fixed="true" data-autoplay="false"> </div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script>(function(d, w, c) {
    w.ChatraID = '5QYmoz7m5kBKqo6Hi';
    var s = d.createElement('script');
    w[c] = w[c] || function() {
        (w[c].q = w[c].q || []).push(arguments);
    };
    s.async = true;
    s.src = 'https://call.chatra.io/chatra.js';
    if (d.head) d.head.appendChild(s);
})(document, window, 'Chatra');

if (false) {
  var chatBtnFn = () => {
    var chatBtn = document.getElementById("chat_btn")
    chatBtn.addEventListener("click", function(){
      Chatra('openChat')
    });
  }
  chatBtnFn()
} else {
  if (false) {
    function chatBtnHide () {
      Chatra('hide')
    }
    function chatBtnShow () {
      Chatra('show')
    }
  }
}</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>